{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b8c87c",
   "metadata": {},
   "source": [
    "## Note: You have to run this notebook to view the visualizations. Alternatively, you may view the view the visualizations in Text Clustering with Top2Vec.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09747763",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a120e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\addison\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea0a50",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b499d5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>altid</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sa1a70ab8ef5</td>\n",
       "      <td>Davenport hits out at Wimbledon</td>\n",
       "      <td>World number one Lindsay Davenport has critic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ta497aea0e36</td>\n",
       "      <td>Camera phones are 'must-haves'</td>\n",
       "      <td>Four times more mobiles with cameras in them ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ta0f0fa26a93</td>\n",
       "      <td>US top of supercomputing charts</td>\n",
       "      <td>The US has pushed Japan off the top of the su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ba23aaa4f4bb</td>\n",
       "      <td>Trial begins of Spain's top banker</td>\n",
       "      <td>The trial of Emilio Botin, the chairman of Sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baa126aeb946</td>\n",
       "      <td>Safety alert as GM recalls cars</td>\n",
       "      <td>The world's biggest carmaker General Motors (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          altid                               title  \\\n",
       "0  sa1a70ab8ef5     Davenport hits out at Wimbledon   \n",
       "1  ta497aea0e36      Camera phones are 'must-haves'   \n",
       "2  ta0f0fa26a93     US top of supercomputing charts   \n",
       "3  ba23aaa4f4bb  Trial begins of Spain's top banker   \n",
       "4  baa126aeb946     Safety alert as GM recalls cars   \n",
       "\n",
       "                                             content  \n",
       "0   World number one Lindsay Davenport has critic...  \n",
       "1   Four times more mobiles with cameras in them ...  \n",
       "2   The US has pushed Japan off the top of the su...  \n",
       "3   The trial of Emilio Botin, the chairman of Sp...  \n",
       "4   The world's biggest carmaker General Motors (...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data = pd.read_csv(\"news_data.csv\")\n",
    "\n",
    "# Verify that we loaded the correct dataset\n",
    "news_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35288400",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce92e849",
   "metadata": {},
   "source": [
    "To cluster the news, we have to first convert its text content into numerical representation i.e. text embeddings. There are several approaches that we can take to create the text embeddings (i.e. term frequency, TF-IDF, Word2Vec, GloVe, Doc2Vec, Universal Sentence Encoder, BERT family of models etc).\n",
    "\n",
    "For this exercise, we will use a pre-trained model from BERT family of models to create the text embeddings for the news. The BERT family of models approach is taken because its models are able to capture the semantic and contextual meaning of the text and also the word order. In particular, we will use the pre-trained model, all-MiniLM-L6-v2 from SentenceTransformers library to create the text embeddings for the news. The choice of model is arbitrary; any model from [here](https://www.sbert.net/docs/pretrained_models.html) should also deliver decent results so long as it was trained on English text.\n",
    "\n",
    "BERT family of models however have a maximum sequence length of 512 tokens due to computational and memory constraints. Our chosen model was trained on data with a maximum sequence length of 128 tokens; it performs best when it is fed with inputs with less than or equal to 128 tokens.\n",
    "\n",
    "Let's check the news dataset to see if any of the news content violates the 128 tokens constraint. If yes, we might need to perform additional processing steps to abide by the constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c514a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
